# -*- coding: utf-8 -*-
"""Mini_Project_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NQHYUuiCGYeK1BnmerSyxvFRm6-Gac8W

1) Importing the dataset
"""

import pandas as pd

df = pd.read_csv("Diabetes.csv")
df.head()

"""2) Checking for null values"""

df.info()

"""3) 
 a)Histogram
"""

import matplotlib.pyplot as plt
df = pd.read_csv("diabetes.csv")

df.hist(figsize=(15,9))
plt.show()

"""3)
 b)Scatter-plot
"""

plt.scatter('Pregnancies','Outcome')
plt.scatter('BMI','Outcome')
plt.scatter('Glucose','Outcome')
plt.scatter('Insulin','Outcome')
plt.scatter('Age','Outcome')
plt.scatter('BloodPressure','Outcome')
plt.show()

"""4)Modelling:
 a)Splitting the dataset using “train-test-split” function.
"""

y = df["Outcome"]
X = df.drop("Outcome", axis=1)

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.25, stratify = y, random_state = 42)

""" b)Applying KNN classification on “Outcome” column of the dataset. """

from sklearn.neighbors import KNeighborsClassifier

model1 = KNeighborsClassifier(n_neighbors = 7)
model1.fit(X_train, y_train)

"""c)Applying Decision Tree Classifier on “Outcome” column of the dataset. """

from sklearn.tree import DecisionTreeClassifier

model2 = DecisionTreeClassifier()
model2.fit(X_train, y_train)

"""d) score on the test set"""

model1.score(X_test, y_test)

model2.score(X_test, y_test)

"""On checking the accuracy score on both the methods we find the accuracy score from the data tree classification is comparitively better the knn classification.

e) Prediction on new data set.
"""

data = pd.read_csv("Diabetes1.csv")

data

model2.predict(data)

